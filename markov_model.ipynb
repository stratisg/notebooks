{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2922877-7414-4271-8f6a-9bea967f66d4",
   "metadata": {},
   "source": [
    "# Research goal\n",
    "We have a dynamical system that is described by the following evolution and measurement equations\n",
    "\\begin{equation}\n",
    "    \\begin{aligned}\n",
    "        x_{t+1} &= a x_{t} \\\\\n",
    "        y_{t} & = x_{t} + \\nu \\,,\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "where $ \\nu $ is normally distributed noise with zero mean and variance $ \\sigma_{\\nu} $. Mathematically that is\n",
    "\\begin{equation}\n",
    "    \\begin{aligned}\n",
    "        \\nu &\\sim \\mathcal{N} (N=\\nu; 0, \\sigma_{\\nu}) \\,,\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "__Note__: We assume that $ \\sigma_{\\nu} $ is known.\n",
    "Having collected a set of measurements $ \\mathcal{Y} = \\{ y_t | t=1, \\dots, N \\} $ we want to estimate the parameter $ a $ in the  evolution equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d195f4-3bf9-4e88-9819-676bc75db5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yorgos/work_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Epoch: 0\tLoss: -5.486E+01\n",
      "===============================================================================\n",
      "Epoch: 100\tLoss: 5.169E+04\n",
      "===============================================================================\n",
      "Epoch: 200\tLoss: 8.527E+08\n",
      "===============================================================================\n",
      "Epoch: 300\tLoss: 6.049E+01\n",
      "===============================================================================\n",
      "Epoch: 400\tLoss: 2.712E+01\n",
      "===============================================================================\n",
      "Epoch: 500\tLoss: 1.027E+07\n",
      "===============================================================================\n",
      "Epoch: 600\tLoss: 2.315E+03\n",
      "===============================================================================\n",
      "Epoch: 700\tLoss: 1.988E+14\n",
      "===============================================================================\n",
      "Epoch: 800\tLoss: 9.819E+18\n",
      "===============================================================================\n",
      "Epoch: 900\tLoss: 1.749E+10\n",
      "===============================================================================\n",
      "Epoch: 1000\tLoss: -1.297E+02\n",
      "===============================================================================\n",
      "Epoch: 1100\tLoss: 2.885E+12\n",
      "===============================================================================\n",
      "Epoch: 1200\tLoss: 2.735E+02\n",
      "===============================================================================\n",
      "Epoch: 1300\tLoss: 4.672E+12\n",
      "===============================================================================\n",
      "Epoch: 1400\tLoss: 8.952E+03\n",
      "===============================================================================\n",
      "Epoch: 1500\tLoss: 9.924E+04\n",
      "===============================================================================\n",
      "Epoch: 1600\tLoss: 2.458E+03\n",
      "===============================================================================\n",
      "Epoch: 1700\tLoss: 1.640E+11\n",
      "===============================================================================\n",
      "Epoch: 1800\tLoss: -1.188E+02\n",
      "===============================================================================\n",
      "Epoch: 1900\tLoss: 1.688E+03\n",
      "===============================================================================\n",
      "Epoch: 1999\tLoss: 1.046E+03\n",
      "===============================================================================\n",
      "AutoNormal.locs.a_param = Parameter containing:\n",
      "tensor(1.0042, requires_grad=True)\n",
      "===============================================================================\n",
      "AutoNormal.scales.a_param = 0.1202240064740181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   6%|â–‹           | 120/2000 [01:53,  1.02s/it, step size=3.58e-04, acc. prob=0.713]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import torch\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer.autoguide import AutoNormal, init_to_mean\n",
    "from utilities import sampling, variational_inference\n",
    "\n",
    "\n",
    "def generate_markov_data(x_init, a_param, std_epsilon, std_nu, total_time):\n",
    "    \"\"\"\n",
    "    True generating process.\n",
    "    \"\"\"\n",
    "    # Timeseries of latent state.\n",
    "    l_x = torch.zeros(total_time)\n",
    "    l_x[0] = x_init\n",
    "\n",
    "    # Evolution and Measurement.\n",
    "    for i_time in range(1, total_time):\n",
    "        l_x[i_time] = a_param * l_x[i_time - 1]\n",
    "        # mean_x = a_param * l_x[i_time - 1]\n",
    "        # l_x[i_time] = Normal(mean_x, std_epsilon).sample()\n",
    "        # In this kind of models we normally do not have measurements of\n",
    "        # the initial state.\n",
    "        # mean_y = l_x[i_time]\n",
    "    l_y = Normal(l_x, std_nu).sample()\n",
    "\n",
    "    return l_x, l_y\n",
    "\n",
    "\n",
    "def model_markov(measurements, mean_a, std_a, x_init, std_epsilon, std_nu,\n",
    "                 total_time):\n",
    "    \"\"\"\n",
    "    True generating process.\n",
    "    \"\"\"\n",
    "    # Timeseries of latent state.\n",
    "    l_x = torch.zeros(total_time)\n",
    "    l_x[0] = x_init\n",
    "    \n",
    "    # Timeseries of measurements.\n",
    "    l_y = torch.zeros(total_time - 1)\n",
    "    \n",
    "    # Prior of evolution parameter.\n",
    "    a_param = pyro.sample(\"a_param\", Normal(mean_a, std_a))\n",
    "    a_ = a_param.clone().detach()\n",
    "    # Evolution and Measurement.\n",
    "    for i_time in range(1, total_time):\n",
    "        l_x[i_time] = a_ * l_x[i_time - 1]\n",
    "        # mean_x = a_param * l_x[i_time - 1]\n",
    "        # l_x[i_time] = pyro.sample(f\"x_{i_time:03d}\",\n",
    "        #                           Normal(mean_x, std_epsilon))\n",
    "        # In this kind of models we normally do not have measurements of\n",
    "        # the initial state.\n",
    "        # mean_y = l_x[i_time]\n",
    "        # pyro.sample(f\"y_{i_time:03d}\", Normal(mean_y, std_nu),\n",
    "        #             obs=measurements[i_time - 1])\n",
    "    with pyro.plate(\"measurements\", total_time):\n",
    "        pyro.sample(f\"y\", Normal(l_x, std_nu),\n",
    "                    obs=measurements)\n",
    "    \n",
    "    return l_x, l_y\n",
    "\n",
    "\n",
    "X_INIT = torch.tensor(1.0)\n",
    "A_TRUE = torch.tensor(0.9)\n",
    "STD_EPSILON = torch.tensor(1e-3)\n",
    "STD_NU = torch.tensor(5e-2)\n",
    "TOTAL_TIME = 100\n",
    "L_TIME = torch.arange(0, TOTAL_TIME)\n",
    "\n",
    "# Plot measurements.\n",
    "state, measurements = generate_markov_data(X_INIT, A_TRUE, STD_EPSILON,\n",
    "                                           STD_NU, TOTAL_TIME)\n",
    "\n",
    "plt.figure(\"Measurements\")\n",
    "plt.plot(L_TIME, measurements, label=\"Measurements\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Measurements (arb. units)\")\n",
    "plt.legend()\n",
    "\n",
    "# Infer variational approximation to the posterior distribution of M.\n",
    "guide = AutoNormal(model_markov, init_loc_fn=init_to_mean())\n",
    "MEAN_A = torch.tensor(1.0)\n",
    "STD_A = torch.tensor(3e-1)\n",
    "\n",
    "# Plot the prior distribution.\n",
    "N_A = 101\n",
    "L_A = torch.linspace(0.0, 2.0, N_A) \n",
    "prob_prior = torch.exp(Normal(MEAN_A, STD_A).log_prob(L_A))\n",
    "plt.figure(\"Parameter distribution\")\n",
    "plt.plot(L_A, prob_prior, label=\"Prior\")\n",
    "model_args = {\"measurements\": measurements, \"mean_a\": MEAN_A, \"std_a\": STD_A,\n",
    "              \"x_init\": X_INIT, \"std_epsilon\": STD_EPSILON, \"std_nu\": STD_NU,\n",
    "              \"total_time\": TOTAL_TIME}\n",
    "optim_args = {\"lr\": 1e-4}\n",
    "N_STEPS = 2000\n",
    "PRINT_EPOCH = 100\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "variational_inference(model_markov, guide, model_args, optim_args,\n",
    "                      n_steps=N_STEPS, print_epoch=PRINT_EPOCH)\n",
    "\n",
    "# Print posterior parameters.\n",
    "for key, val in pyro.get_param_store().items():\n",
    "    print(79 * \"=\")\n",
    "    print(f\"{key} = {val}\")\n",
    "mu_mean_posterior = pyro.param(\"AutoNormal.locs.a_param\")\n",
    "std_mean_posterior = pyro.param(\"AutoNormal.scales.a_param\")\n",
    "\n",
    "# MCMC sampling.\n",
    "sampler_args = {\"num_samples\": int(1e3), \"warmup_steps\": int(1e3)}\n",
    "samples = sampling(model_markov, sampler_args, model_args)\n",
    "\n",
    "# Plotting the posterior.\n",
    "plt.figure(\"Parameter distribution\")\n",
    "plt.hist(samples, density=True, label=\"Posterior\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2c6ad-fe52-4301-8034-d0ea89c4e138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
